{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import TensorDataset\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(s):\n",
    "    # Remove extra space\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    # Remove too short review\n",
    "    if len(s.split(' ')) < 15:\n",
    "        return '!'\n",
    "    return s\n",
    "\n",
    "#df = pd.read_table('../HW1/data/amazon_reviews_us_Office_Products_v1_00.tsv', on_bad_lines='skip', usecols=['star_rating', 'review_body'], dtype={'star_rating':'str', 'review_body':'str'}).dropna()\n",
    "df = pd.read_table('data.tsv', on_bad_lines='skip', usecols=['star_rating', 'review_body'], dtype={'star_rating':'str', 'review_body':'str'}).dropna()\n",
    "df['content'] = df['review_body'].apply(lambda context: cleaning(context))\n",
    "\n",
    "class_label = []\n",
    "too_short_index = []\n",
    "for index, row in df.iterrows():\n",
    "    if int(row['star_rating']) > 3:\n",
    "        class_label.append(1)\n",
    "    else:\n",
    "        class_label.append(0)\n",
    "df['class_label'] = class_label\n",
    "df2 = df.drop(df[df['content'] == '!'].index)\n",
    "df2.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv('cleaned_data.csv')\n",
    "df3 = df2.groupby(\"class_label\").sample(n = 50000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for s in df3['content']:\n",
    "    cur = s.split(' ')\n",
    "    sentences.append(cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')\n",
    "pairs = [\n",
    "    ('great', 'good'),\n",
    "    ('large', 'huge'),\n",
    "    ('concern', 'worry')   \n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r, %r, %.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=sentences, vector_size=300, window=13, min_count=9)\n",
    "for w1, w2 in pairs:\n",
    "    print('%r, %r, %.2f' % (w1, w2, model.wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What do you conclude from comparing vectors generated by yourself and the pretrained model? <br>\n",
    "Ans: According to the similarities comparison between our training model and the pretrained model, the similarity of every similar pair from pretrained one is better. I would like to assume that this differences could result from the dataset. The pretrained model's training data could be more dynamic, and our amazon's review data could somehow being ordinary (since they're all feedbacks about products). <br>\n",
    "### Q: Which of the Word2Vec models seems to encode semantic similarities between words better?<br>\n",
    "Ans: The \"“word2vec-googlenews-300\" pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_V = df3['class_label'].to_numpy()\n",
    "content_V = df3['content'].to_numpy()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_V = tfidf_vectorizer.fit_transform(content_V).toarray()\n",
    "print(tfidf_V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2V_features(content_V):\n",
    "    res = []\n",
    "    for i, s in enumerate(content_V):\n",
    "        words = s.split(' ')\n",
    "        cur = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                cur.append(wv[w])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        cur = np.array(cur)\n",
    "        res.append(np.mean(cur, axis=0))\n",
    "    return np.array(res)\n",
    "word2V_V = word2V_features(content_V)\n",
    "print(word2V_V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2V_train, word2V_test, word2V_label_train, word2V_label_test = train_test_split(word2V_V, label_V, test_size=0.2, random_state=1)\n",
    "tfidf_train, tfidf_test, tfidf_label_train, tfidf_label_test = train_test_split(tfidf_V, label_V, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_result(tn, fp, fn, tp):\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 / ((1 / precision) + (1 / recall))\n",
    "    return acc, precision, recall, f1\n",
    "    \n",
    "model = Perceptron(max_iter=1000)\n",
    "model.fit(word2V_train, word2V_label_train)\n",
    "predictions_test = model.predict(word2V_test)\n",
    "tn, fp, fn, tp = confusion_matrix(word2V_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"Word2Vec Perceptron accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(max_iter=1000)\n",
    "model.fit(tfidf_train, tfidf_label_train)\n",
    "predictions_test = model.predict(tfidf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(tfidf_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"TF-IDF Perceptron accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(max_iter=1000)\n",
    "model.fit(word2V_train, word2V_label_train)\n",
    "predictions_test = model.predict(word2V_test)\n",
    "tn, fp, fn, tp = confusion_matrix(word2V_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"Word2Vec SVM accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(max_iter=1000)\n",
    "model.fit(tfidf_train, tfidf_label_train)\n",
    "predictions_test = model.predict(tfidf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(tfidf_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"TF-IDF SVM accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What do you conclude from comparing performances for the models trained using the two different feature types? <br>\n",
    "Ans: TF-IDF has the better accuracy result for both model than word2Vec. For word2Vec features, SVM has better result than perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        feature = self.data[index].astype('float32').reshape((-1, 1))\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            feature = self.transform(feature)\n",
    "        \n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerMLP(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super().__init__()\n",
    "        self.D_in = D_in\n",
    "        self.fc1 = nn.Linear(D_in, H1)\n",
    "        self.fc2 = nn.Linear(H1, H2)\n",
    "        self.fc3 = nn.Linear(H2, D_out)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.D_in)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 32, 'shuffle': True}\n",
    "\n",
    "train_data = myDataset(word2V_train, word2V_label_train, transform=transforms.ToTensor())\n",
    "test_data = myDataset(word2V_test, word2V_label_test, transform=transforms.ToTensor())\n",
    "train_data_generator = DataLoader(train_data, **params)\n",
    "test_data_generator = DataLoader(test_data, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPmodel = TwoLayerMLP(300, 50, 5, 2)\n",
    "print(MLPmodel)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(MLPmodel.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    MLPmodel.load_state_dict(torch.load('model_4a.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "MLPmodel.train()\n",
    "max_epochs = 100\n",
    "min_loss = np.Inf\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    test_loss = 0.0\n",
    "    for data, target in train_data_generator:\n",
    "        optimizer.zero_grad()\n",
    "        output = MLPmodel(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    MLPmodel.eval()\n",
    "    for data, target in test_data_generator:\n",
    "        output = MLPmodel(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "    test_loss = test_loss/len(test_data_generator.dataset)\n",
    "    scheduler.step(test_loss/len(test_data_generator))\n",
    "    if epoch == 0:\n",
    "        min_loss = test_loss\n",
    "    if test_loss < min_loss:\n",
    "        min_loss = test_loss\n",
    "        torch.save(MLPmodel.state_dict(), 'model_4a.pt')\n",
    "        print(\"Model saved. Loss = \", min_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(MLPmodel, dataloader):\n",
    "    total = 0\n",
    "    match = 0\n",
    "    for data, target in dataloader:\n",
    "        outputs = MLPmodel(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for a, b in zip(target, predicted):\n",
    "            total += 1\n",
    "            if a == b:\n",
    "                match += 1 \n",
    "    return match / total\n",
    "\n",
    "try:\n",
    "    MLPmodel.load_state_dict(torch.load('model_4a.pt'))\n",
    "except:\n",
    "    pass\n",
    "MLPmodel.eval()\n",
    "acc = cal_acc(MLPmodel, test_data_generator)\n",
    "print(\"Word2Vec Feedforward Neural Networks accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_word2V_features(content_V):\n",
    "    res = []\n",
    "    for i, s in enumerate(content_V):\n",
    "        words = s.split(' ')\n",
    "        cur = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                cur.append(wv[w])\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if len(cur) >= 10:\n",
    "                break\n",
    "        while len(cur) < 10:\n",
    "            cur.append([0 for _ in range(300)])\n",
    "        cur = np.array(cur)\n",
    "        res.append(cur)\n",
    "    return np.array(res)\n",
    "\n",
    "concat_word2Vec_V = concat_word2V_features(content_V)\n",
    "print(concat_word2Vec_V.shape)\n",
    "concat_word2V_train, concat_word2V_test, concat_word2V_label_train, concat_word2V_label_test = train_test_split(concat_word2Vec_V, label_V, test_size=0.2, random_state=32)\n",
    "concat_train_data = myDataset(concat_word2V_train, concat_word2V_label_train, transform=transforms.ToTensor())\n",
    "concat_test_data = myDataset(concat_word2V_test, concat_word2V_label_test, transform=transforms.ToTensor())\n",
    "concat_train_data_generator = DataLoader(concat_train_data, **params)\n",
    "concat_test_data_generator = DataLoader(concat_test_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_MLPmodel = TwoLayerMLP(3000, 50, 5, 2)\n",
    "concat_criterion = nn.CrossEntropyLoss()\n",
    "concat_optimizer = torch.optim.SGD(concat_MLPmodel.parameters(), lr=0.1)\n",
    "concat_scheduler = ReduceLROnPlateau(concat_optimizer, 'min', patience = 5)\n",
    "\n",
    "try:\n",
    "    concat_MLPmodel.load_state_dict(torch.load('model_4b.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "max_epochs = 100\n",
    "min_loss = np.Inf\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    test_loss = 0.0\n",
    "    concat_MLPmodel.train()\n",
    "    for data, target in concat_train_data_generator:\n",
    "        concat_optimizer.zero_grad()\n",
    "        output = concat_MLPmodel(data)\n",
    "        loss = concat_criterion(output, target)\n",
    "        loss.backward()\n",
    "        concat_optimizer.step()\n",
    "    \n",
    "    concat_MLPmodel.eval()\n",
    "    for data, target in concat_test_data_generator:\n",
    "        output = concat_MLPmodel(data)\n",
    "        loss = concat_criterion(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "    test_loss = test_loss/len(concat_test_data_generator.dataset)\n",
    "    concat_scheduler.step(test_loss/len(concat_test_data_generator))\n",
    "    if epoch == 0:\n",
    "        min_loss = test_loss\n",
    "    if test_loss < min_loss:\n",
    "        min_loss = test_loss\n",
    "        torch.save(concat_MLPmodel.state_dict(), 'model_4b.pt')\n",
    "        print(\"Model saved. Loss = \", min_loss)\n",
    "\n",
    "try:\n",
    "    concat_MLPmodel.load_state_dict(torch.load('model_4b.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "concat_MLPmodel.eval()\n",
    "acc = cal_acc(concat_MLPmodel, concat_test_data_generator)\n",
    "print(\"Concat Word2Vec Feedforward Neural Networks accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What do you conclude by comparing accuracy values you obtain with those obtained in the “’Simple Models” section? <br>\n",
    "Ans: The \"mean\" feature has better result than \"concatenate\" feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_word2V_features(content_V):\n",
    "    res = []\n",
    "    for i, s in enumerate(content_V):\n",
    "        words = s.split(' ')\n",
    "        cur = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                cur.append(wv[w])\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if len(cur) >= 10:\n",
    "                break\n",
    "        while len(cur) < 10:\n",
    "            cur.append([0 for _ in range(300)])\n",
    "        cur = np.array(cur)\n",
    "        res.append(cur)\n",
    "    return np.array(res)\n",
    "\n",
    "rnn_data = rnn_word2V_features(content_V)\n",
    "print(rnn_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sentence, label, model, learning_rate):\n",
    "    model.train()\n",
    "    hidden = model.initHidden()\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long)\n",
    "    model.zero_grad()\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        input_tensor = torch.from_numpy(sentence[i].astype('float32')).view(-1, 300)\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "\n",
    "    loss = criterion(output, label_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sentence, label, model):\n",
    "    model.eval()\n",
    "    hidden = model.initHidden()\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        input_tensor = torch.from_numpy(sentence[i].astype('float32')).view(-1, 300)\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "\n",
    "    loss = criterion(output, label_tensor)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_train, rnn_test, rnn_label_train, rnn_label_test = train_test_split(rnn_data, label_V, test_size=0.2, random_state=32)\n",
    "n_hidden = 10\n",
    "rnn = RNN(300, n_hidden, 2)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.01\n",
    "max_epoch = 1\n",
    "min_loss = np.Inf\n",
    "train_size = len(rnn_data)\n",
    "load_trained = False\n",
    "\n",
    "try:\n",
    "    rnn.load_state_dict(torch.load('model_5a.pt'))\n",
    "    load_trained = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for epoch in tqdm(range(max_epoch)):\n",
    "    cur_loss = 0\n",
    "    for sentence, label in zip(rnn_train, rnn_label_train):\n",
    "        output, loss = train(sentence, label, rnn, learning_rate)\n",
    "    \n",
    "    for sentence, label in zip(rnn_test, rnn_label_test):\n",
    "        output, loss = test(sentence, label, rnn)\n",
    "        cur_loss += loss\n",
    "    cur_loss = cur_loss / train_size\n",
    "    if epoch == 0:\n",
    "        min_loss = cur_loss\n",
    "        if not load_trained:\n",
    "            torch.save(rnn.state_dict(), 'model_5a.pt')\n",
    "    elif cur_loss < min_loss:\n",
    "        min_loss = cur_loss\n",
    "        torch.save(rnn.state_dict(), 'model_5a.pt')\n",
    "    print(\"Model saved. Loss = \", min_loss)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_acc(test_data, test_labels, model):\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for sentence, label in zip(test_data, test_labels):\n",
    "        hidden = model.initHidden()\n",
    "        for i in range(len(sentence)):\n",
    "            input_tensor = torch.from_numpy(sentence[i].astype('float32')).view(-1, 300)\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += 1\n",
    "        if predicted == label:\n",
    "            match += 1\n",
    "\n",
    "    return match / total\n",
    "try:\n",
    "    rnn.load_state_dict(torch.load('model_5a.pt'))\n",
    "except:\n",
    "    pass\n",
    "acc = evaluate_test_acc(rnn_test, rnn_label_test, rnn)\n",
    "print(\"RNN accuracy: {:.3f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(rnn_train), torch.from_numpy(rnn_label_train))\n",
    "test_data = TensorDataset(torch.from_numpy(rnn_test), torch.from_numpy(rnn_label_test))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(GRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.GRU(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_epoch = 10\n",
    "min_loss = np.Inf\n",
    "train_size = len(rnn_data)\n",
    "clip = 5\n",
    "\n",
    "gru = GRU(300, 2, 10, 1)\n",
    "learning_rate = 0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)\n",
    "\n",
    "try:\n",
    "    gru.load_state_dict(torch.load('model_5b.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gru.train()\n",
    "for epoch in tqdm(range(max_epoch)):\n",
    "    cur_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        h = gru.init_hidden(inputs.shape[0])\n",
    "        gru.zero_grad()\n",
    "        x = inputs.to(torch.float32)\n",
    "        output, h = gru(x, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(gru.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    \n",
    "    gru.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        h = gru.init_hidden(inputs.shape[0])\n",
    "        x = inputs.to(torch.float32)\n",
    "        output, h = gru(x, h)\n",
    "        test_loss = criterion(output.squeeze(), labels.float())\n",
    "        cur_loss += test_loss.item()\n",
    "\n",
    "    cur_loss = cur_loss / len(test_loader)\n",
    "    if epoch == 0:\n",
    "        min_loss = cur_loss\n",
    "    elif epoch != 0 and cur_loss < min_loss:\n",
    "        min_loss = cur_loss\n",
    "        torch.save(gru.state_dict(), 'model_5b.pt')\n",
    "        print(\"Model saved. Loss = \", min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    gru.load_state_dict(torch.load('model_5b.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "num_correct = 0\n",
    "gru.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = gru.init_hidden(inputs.shape[0])\n",
    "    x = inputs.to(torch.float32)\n",
    "    output, h = gru(x, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"GRU accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_epoch = 10\n",
    "min_loss = np.Inf\n",
    "train_size = len(rnn_data)\n",
    "clip = 5\n",
    "\n",
    "lstm = LSTM(300, 2, 10, 1)\n",
    "learning_rate = 0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "try:\n",
    "    lstm.load_state_dict(torch.load('model_5c.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "lstm.train()\n",
    "for epoch in tqdm(range(max_epoch)):\n",
    "    cur_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        h = lstm.init_hidden(inputs.shape[0])\n",
    "        h = tuple([e.data for e in h])\n",
    "        lstm.zero_grad()\n",
    "        x = inputs.to(torch.float32)\n",
    "        output, h = lstm(x, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(lstm.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    \n",
    "    lstm.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        h = lstm.init_hidden(inputs.shape[0])\n",
    "        h = tuple([each.data for each in h])\n",
    "        x = inputs.to(torch.float32)\n",
    "        output, h = lstm(x, h)\n",
    "        test_loss = criterion(output.squeeze(), labels.float())\n",
    "        cur_loss += test_loss.item()\n",
    "\n",
    "    cur_loss = cur_loss / len(test_loader)\n",
    "    if epoch == 0:\n",
    "        min_loss = cur_loss\n",
    "    elif epoch != 0 and cur_loss < min_loss:\n",
    "        min_loss = cur_loss\n",
    "        torch.save(lstm.state_dict(), 'model_5c.pt')\n",
    "        print(\"Model saved. Loss = \", min_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lstm.load_state_dict(torch.load('model_5c.pt'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "num_correct = 0\n",
    "lstm.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = lstm.init_hidden(inputs.shape[0])\n",
    "    h = tuple([each.data for each in h])\n",
    "    x = inputs.to(torch.float32)\n",
    "    output, h = lstm(x, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"LSTM accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What do you conclude by comparing accuracy values you obtain by GRU, LSTM, and simple RNN? <br>\n",
    "Ans: GRU and LSTM have better result than simple RNN, looks like long term memories indeed effect the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Accuracy <br>\n",
    "Perceptron: 76.9% <br>\n",
    "SVM: 79.9% <br>\n",
    "NN(mean): 79.8% <br>\n",
    "NN(concat): 71.9% <br>\n",
    "RNN: 70.9% <br>\n",
    "LRU: 76.2% <br>\n",
    "LSTM: 76.4%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS544",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
